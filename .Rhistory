dl_range_df <- rbind(dl_range_df, dl_range)
if (kx == 3){
x = x+0.1666
kx = 0
}
else {
x = x+0.1667
}
kx = kx + 1
}
if (ky == 3){
y = y+0.16666
ky = 0
}
else {
y = y+0.16667
}
ky = ky + 1
}
}
colnames(dl_min_df) <- c("x", "y", paste0("dl_annual_min"))
colnames(dl_max_df) <- c("x", "y", paste0("dl_annual_max"))
colnames(dl_range_df) <- c("x", "y", paste0("dl_annual_range"))
abiotics_df <- merge(abiotics_df, dl_min_df, by = c("x", "y"))
abiotics_df <- merge(abiotics_df, dl_max_df, by = c("x", "y"))
abiotics_df <- merge(abiotics_df, dl_range_df, by = c("x", "y"))
#finalize
abiotics_df <- abiotics_df %>%
filter(y<maxlat, y>(minlat), x>(minlong), x<maxlong)
abiotics_df <-na.omit(abiotics_df) #remove NA values
abiotics_df <-subset(abiotics_df)#, ph_max!=0 & ph_min!=0 & ph_avg!=0) #remove null ph values
return(abiotics_df)
}
occ_rescaling <- function(data_cl, minlat, maxlat , minlong, maxlong, resolution){
point<-st_as_sf(data_cl, coords = c("decimalLongitude", "decimalLatitude"), crs ="WGS84")
# Create an empty raster (vals = 0) at 30 arcmins (res = 0.5)  in WGS84 (crs(point))
if (resolution == 30){
rast <- raster(crs = crs(point), vals=0,resolution = c(0.5, 0.5))
# Rasterization (Presence map) and stocking the results in a multi-layers raster brick
brick_rast <- brick(nrows=nrow(rast),ncol=ncol(rast),nl=length(unique(point$species))) #nl = create as many layers as different species
}
if (resolution == 10){
rast <- raster(crs = crs(point), vals=0,resolution = c(1/6, 1/6))
# Rasterization (Presence map) and stocking the results in a multi-layers raster brick
brick_rast <- brick(nrows=nrow(rast),ncol=ncol(rast),nl=length(unique(point$species))) #nl = create as many layers as different species
}
#for each species, rasterize the occurence points in 30 arcmins rasterbricks and get a dataframe
for(i in 1:length(unique(point$species))){ #might be long
point.i<-point[point$species==unique(point$species)[i],] #point.i is a "sf" dataframe with all the occurence pints of species i
brick_rast[[i]]<-rasterize(as(point.i, "Spatial"),rast,field=1)
df <- as.data.frame(brick_rast[[i]], xy=TRUE, centroids = TRUE)
df <- df %>%
filter(y<maxlat, y>(minlat), x>(minlong), x<maxlong) #spatial filter (already done before)
write.table(df, file = paste(as.character(unique(point$species)[i]),"_30.csv"), row.names=FALSE, sep=";",dec=",", na=" ")  #create a csv file for each species : x/Y/species -> species value takes values Na (if absent) or 1 (if present)
colnames(df)[3] <- c("species")
df$species[df$species==1] <- as.character(unique(point$species)[i]) #if the species is present(=1) replace "1" with species name
df <-na.omit(df) #remove NA
species_df <- rbind(species_df, df) #add to the global dataframe
}
return(species_df)
}
abiotics_species_merge <- function(abiotics_df, species_df, selected_abiotics) {
#select variables from abiotics df to have x and y  (annual_rangeT, annual_meanT, annual_prec_wc, ph_max, maxT_WM, srad_30, prec_DM_wc, prec_seasonality_wc, flow_avg (range?), elevation, slope)
selected_abiotics_df <- cbind(abiotics_df[c(1,2)], abiotics_df[selected_abiotics])
#merge and crop datasets to obtain columns as : Species / var 1 / var 2 / ...
species_abiotics_df <- data.frame(matrix(ncol = length(names(selected_abiotics_df)), nrow = 0))
column_names <- names(selected_abiotics_df)[3:length(names(selected_abiotics_df))]
colnames(species_abiotics_df) <- c("species", column_names)
for (i in 1:length(species_list)){
species <- species_df[species_df$species==unique(species_df$species)[i],]
species_name <- merge(species, selected_abiotics_df, by=c("x","y")) #merge species i with factors data frame
colnames(species_name)[3] <- c("species")                          #rename "species name" column
species_name$species[species_name$species==1] <- as.character(unique(species_df$species)[i]) #replace cell with value = 1 with the species name
species_name <-na.omit(species_name)                                #remove NA
species_name <- species_name[,-(1:2)]                               #remove x and y columns
species_abiotics_df <-rbind(species_abiotics_df, species_name)
}
return(species_abiotics_df)
}
info_DB <- function(databases_to_use){
if ("EarthEnv" %in% databases_to_use ){
browseURL("https://data.earthenv.org/streams/ReadMe.txt")
}
if ("WorldClim" %in% databases_to_use ){
browseURL("https://www.worldclim.org/data/worldclim21.html")
}
if ("FLO1K" %in% databases_to_use ){
browseURL("https://www.nature.com/articles/sdata201852")
}
}
#function that takes a list of hypervolumes and returns an hypervolume corresponding to their intersection
HV_intersection <- function (hv_list, num.points.max = NULL, verbose = TRUE, check.memory = TRUE,
distance.factor = 1) {
library(purrr) #to use reduce()
########################################################################################################################
np_list <- c()
hv_point_density_list <- c()
dimhv_list <- c()
hv_names_list <- c()
#run through all the hypervolume and for each one store the data in the lists
for (i in 1:length(hv_list@HVList)){
hv_names_list <- c(hv_names_list, hv_list[[i]]@Name)
np <- nrow(hv_list[[i]]@RandomPoints)          #get number of random points
hv_point_density <- np/hv_list[[i]]@Volume     #calculate point density
dimhv = ncol(hv_list[[i]]@RandomPoints)        #get dimensionality
if (is.nan(hv_point_density)) {
hv_point_density <- NA
}
#add the data to the lists
np_list <- c(np_list, np)
hv_point_density_list <- c(hv_point_density_list, hv_point_density)
dimhv_list <- c(dimhv_list, dimhv)
}
#check that each dimensionality is the same as the dimensionality of the 1st HV
for (i in 2:length(dimhv_list)){
if (dimhv_list[i] != dimhv_list[1]) {
stop("Dimensionality of hypervolumes is not the same.")
}
}
dim = dimhv_list[1]   #dim is the unique dimensionality
#calculate max number of points according to dimensionality
if (is.null(num.points.max)) {
num.points.max = ceiling(10^(3 + sqrt(hv_list[[i]]@Dimensionality)))
if (verbose == TRUE) {
cat(sprintf("Choosing num.points.max=%.0f (use a larger value for more accuracy.)\n",
num.points.max))
}
}
#get the density of the HV with minimum points density
density_list <- c()
for (i in 1:length(hv_point_density_list)){
density_list <- c(density_list, hv_point_density_list[i], num.points.max/hv_list[[i]]@Volume)
mindensity = min(density_list,
na.rm = T)
}
if (verbose == TRUE) {
cat(sprintf("Using minimum density of %f\n", mindensity))
}
#for each HV, keep the number of points that gives the same density to each HV according to their volume
numpointstokeep_hv_list <- c()
for (i in 1:length(hv_list@HVList)){
numpointstokeep_hv <- floor(mindensity*hv_list[[i]]@Volume)
numpointstokeep_hv_list <- c(numpointstokeep_hv_list, numpointstokeep_hv)
}
####################################################################################################################
###   check that no HV is  HV are empty
####################################################################################################################
is_any_pointstokeep_null = FALSE
nopointstokeep <- c()
for (i in 1:length(numpointstokeep_hv_list)){
if (numpointstokeep_hv_list[i] == 0 | is.null(numpointstokeep_hv_list[i])){
is_any_pointstokeep_null = TRUE
nopointstokeep <- c(nopointstokeep, i)
}
}
if (is_any_pointstokeep_null == TRUE){
stop(paste0("hv",nopointstokeep,"has no random points and is empty."))
}
#####################################################################################################################
#####################################################################################################################
#subsample all hypervolumes to get same points density
hv_points_ss_list <- list()
for (i in 1:length(hv_list@HVList)){
hv_points_ss = hv_list[[i]]@RandomPoints[sample(1:np_list[i], size = numpointstokeep_hv_list[i]),
, drop = FALSE] #randomly select points with as many points as the numpointstokeep is equal to
hv_points_ss_list[[i]] <- hv_points_ss
}
point_density = nrow(hv_points_ss_list[[1]])/hv_list[[1]]@Volume
cutoff_dist = point_density^(-1/dim) * distance.factor
#####################################################################################################################
#####################################################################################################################
if (verbose == TRUE) {
cat("Beginning ball queries... \n")
}
#get all the points of the HVs in a single set
total_hv_points_ss <- c()
for (i in 1:length(hv_points_ss_list)){
total_hv_points_ss <- rbind (total_hv_points_ss, as.data.frame(hv_points_ss_list[[i]]))
}
total_hv_points_ss <-  as.matrix(total_hv_points_ss )
intersection_hv_points <-c()
volume_intersection_list <- c()
final_points_intersection_list <- c()
#compare the set to the resampled HVs, individually
for (i in 1:length(hv_points_ss_list)){
hv_points_in_i_all <- evalfspherical(data = hv_points_ss_list[[i]], radius = cutoff_dist,
points =  total_hv_points_ss )
hv_points_in_i = as.data.frame(total_hv_points_ss)[hv_points_in_i_all > 0,
, drop = FALSE]
final_points_intersection_list[[i]] <- hv_points_in_i
}
#keep only the points that are common for all the dataframes of the list
final_points_intersection <- unique(reduce(final_points_intersection_list, inner_join))
#resample the points dividing their number by the number of hypervolumes compared
num_points_to_sample_in_intersection = nrow(final_points_intersection)/length(hv_points_ss_list)
final_points_intersection = final_points_intersection[sample(1:nrow(final_points_intersection),
size = num_points_to_sample_in_intersection ), , drop = FALSE]
final_volume_intersection <- nrow(p_in_intersection)/ mindensity
#generate a new HV corresponding to the overlap between all the input HVs
result = new("Hypervolume")
result@Method = "Set operations"
result@Data = matrix(NaN, nrow = 1, ncol = dim)
result@Dimensionality = dim
result@Volume = final_volume_intersection
result@PointDensity = mindensity
result@Parameters = list()
result@RandomPoints = matrix(as.matrix(as.data.frame(final_points_intersection)),
ncol = dim)
result@ValueAtRandomPoints = rep(1, nrow(result@RandomPoints))
return(result)
}
#function to rescale
rescale.many <- function(dat, column.nos) {
nms <- names(dat)
for(col in column.nos) {
name <- paste(nms[col],".rescaled", sep = "")
dat[nms[col]] <- rescale(dat[,col])
}
cat(paste("Rescaled ", length(column.nos)," variable(s)"))
dat
}
set_pca_axis <- function(species_abiotics_df, nb_variables){
rescaled_abiotics <- rescale.many(species_abiotics_df, c(2:(nb_variables+1)))
rescaled_abiotics_save <- rescaled_abiotics
rescaled_abiotics$species = as.numeric(as.factor(rescaled_abiotics$species))
####test package factoextra
res <- prcomp(rescaled_abiotics, scale = TRUE)
#Npc = number of principal components retained
# Kaiser-Guttman rule. A modified rule suggest an acceptance from over 0.7
Npc <- as.numeric(summary(res$sd^2 > 1)["TRUE"])
####test package ade4
res <- dudi.pca(df = rescaled_abiotics, scannf = FALSE, nf = Npc)
rescaled_abiotics <- cbind(rescaled_abiotics_save$species , data.frame(res$li))
#variables_axis <- data.frame(res$co)
axis_names <- c()
for (i in 1:Npc){
axis_names <- c(axis_names, paste0("Axis", i))
}
colnames(rescaled_abiotics) <- c("species", axis_names)
return(rescaled_abiotics)
}
clustering <- function(abiotics_df) {
require(shiny)
method_names <- c("single", "complete", "average")
variable_names <- c("annual_meanT", "T_seasonality", "maxT_WM", "minT_CM", "annual_rangeT", "meanT_DQ", "annual_prec", "prec_WM", "prec_DM", "prec_seasonality", "ph_max", "elevation_avg", "slope_avg", "flow_df_av", "flow_df_mi", "flow_df_ma", "srad", "vapr", "dl_annual_min", "dl_annual_max", "dl_annual_range")
variable_names_display<- c("annual mean Temperature", "Temperature seasonality", "maximum Temperature of the Warmest month","minimum Temperature of the Coldest month","Temperature_annual_range","mean Temperature of the Driest quarter", "annual precipitation", "precipitation of the Wettest month", "precipitation of the Driest month", "precipitations seasonality","maximum ph of the soil", "elevation average", "slope average", "average flow","minimum flow","maximum flow", "solar radiations", "water vapor pressure", "daylength annual min", "daylength annual max", "daylength annual range")
abiotics_df_sub <- abiotics_df[,-(1:2)] #remove x and y columns
shinyApp(
ui <- fluidPage(
titlePanel("Correlations"),
sidebarLayout(
sidebarPanel(
selectInput(inputId = "Method",
label = "Choose method:",
choices = method_names),
numericInput("threshold", "Threshold value :", 0.7, min = 0, max = 1),
verbatimTextOutput("value"),
checkboxGroupInput(inputId = "Factor",
label = "Choose factors to keep:",
choiceNames = variable_names_display,
choiceValues = variable_names),
actionButton(inputId= "submit", label= "submit")
),
# Main panel for displaying outputs ----
mainPanel(
plotOutput("plot1", width = "100%", height = 600)
)
)
),
server <- function(input, output) {
output$plot1 <- renderPlot({
BioClust <- varclus (as.matrix (abiotics_df_sub) , similarity = "spearman", method = input$Method)
plot (BioClust, hang=-1)
abline(h= 1-input$threshold,lwd=2,col="red")
})
observeEvent(input$submit, {
selected_abiotics <<- input$Factor
})
}
)
}
generate_species_hypervolumes <- function(species_list_selected, rescaled_abiotics, nb_axis){
hv_list <- c() #a list to be filled with all the species hypervolumes
for (i in 1:length(species_list_selected)){
data <- subset(rescaled_abiotics, species==species_list_selected[i])[,2:(nb_axis+1)]
print(species_list_selected[i])
print(i)
if (length(data[[1]])>100){  #if there are not enough occurences, an error would appear
hv_species <- hypervolume(data, method='svm')
hv_species@Name <- species_list_selected[[i]]
hv_list<- hypervolume_join(hv_list, hv_species)
}
else {
warning(paste0(species_list_selected[i], "does not have enough values to be studied and has been removed from the list"))
}
}
return(hv_list)
}
hypervolume_overlap <- function(list_combi, nb_combi, hv_list, species_list_hv_selected){
combi_df <- data.frame(matrix(ncol = nb_combi, nrow = 0))
for ( i in 1:length(list_combi)){
vect <- list_combi[[i]]
length(vect) <- nb_combi+1
combi_df <- rbind(combi_df, vect)
}
combi_df[is.na(combi_df)] <- "None"
for (i in 1:length(combi_df[,1])){
ind <- c()
hv_list_test <- new("HypervolumeList")
for (j in 1:length(species_list_hv_selected)){
for (q in 1:length(combi_df[1,])){
if (combi_df[[q]][i] == hv_list[[j]]@Name){
ind <- c(ind, j)
}
}
}
hv_list_test <-  hv_list[[ind]]
intersection <- HV_intersection(hv_list_test)
combi_df[[nb_combi+1]][i] <- intersection@Volume
}
#rescale
combi_df[[nb_combi+1]] <- as.numeric(combi_df[[nb_combi+1]])
rescaled_combi_df <- rescale.many(combi_df, nb_combi+1)
#species_abiotics_df_sub <- rescaled_abiotics_save %>% filter(
#species %in% c(species_list_hv_selected)
#)
#rescaled_abiotics_df <- rescale.many(species_abiotics_df_sub, c(2:11))
return(rescaled_combi_df)
}
Shiny_HV_overlap <- function(species_list_hv_selected,nb_combi, selected_abiotics, rescaled_combi_df, species_abiotics_df){
shinyApp(
ui = fluidPage(
titlePanel("Species compatibility"),
sidebarLayout(
sidebarPanel(
selectInput(inputId = "central_species",
label = "Choose a central species:",
choices = c("None", species_list_hv_selected)),
selectInput(inputId = "nb_species",
label = "Choose a number of species:",
choices = 2:as.numeric(nb_combi)),
selectInput(inputId = "nb_combi_display",
label = "Choose the number of best combinations to display:",
choices = 5:50),
selectInput(inputId = "Factor",
label = "Choose a factor:",
choices = selected_abiotics),
checkboxGroupInput(inputId = "species_show",
label = "Chose species to show:",
choiceNames = species_list_hv_selected,
choiceValues = species_list_hv_selected)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: HTML table with requested number of observations ----
plotOutput("plot1", width = "100%", height = 600),
plotOutput("plot2", width = "100%", height = 400)
)
)
),
#### set server #####
server = function(input, output) {
selected_species <- species_list_hv_selected
#static background map
output$plot1 <- renderPlot({
if (input$central_species == "None"){
combi_df_sp <- data.frame(matrix(ncol = as.numeric(input$nb_species), nrow = 0))
for (i in 1:length(rescaled_combi_df[,1])){
n <- rowSums(rescaled_combi_df == "None")
if ((nb_combi - n[i]) == as.numeric(input$nb_species)){
vect <- rescaled_combi_df[i,]
combi_df_sp <- rbind(combi_df_sp, vect)
}
}
best_combi <- combi_df_sp %>% arrange(desc(as.numeric(combi_df_sp[[nb_combi+1]]))) %>% ## on classe par ordre d?croissant
slice(1:input$nb_combi_display) ## on s?lectionne les 5 premi?res lignes (les plus hautes)
}
else{
row_sub = apply(rescaled_combi_df, 1, function(row) all(row != input$central_species ))
combi_df_sub <- rescaled_combi_df[!row_sub,]
combi_df_central_sp <- data.frame(matrix(ncol = as.numeric(input$nb_species), nrow = 0))
for (i in 1:length(combi_df_sub[,1])){
n <- rowSums(combi_df_sub == "None")
if ((nb_combi - n[i]) == as.numeric(input$nb_species)){
vect <- combi_df_sub[i,]
combi_df_central_sp <- rbind(combi_df_central_sp, vect)
}
}
best_combi <- combi_df_central_sp %>% arrange(desc(as.numeric(combi_df_central_sp[[nb_combi+1]]))) %>% ## on classe par ordre d?croissant
slice(1:input$nb_combi_display) ## on s?lectionne les 5 premi?res lignes (les plus hautes)
}
names_list <- c()
for (i in 1:length(best_combi[,1])){
combi_name <- c()
for (j in 1:(length(best_combi[1,])-1)){
if (best_combi[[j]][i] != "None"){
combi_name <- paste(combi_name,  best_combi[[j]][i], sep = "\n")
}
}
names_list <- c(names_list, combi_name)
}
best_combi<- cbind(best_combi, names_list)
colnames(best_combi)[nb_combi+1] <- c("Intersection_volume")
colnames(best_combi)[nb_combi+2] <- c("names_list")
ggplot(data = best_combi, aes(x = reorder(names_list,-Intersection_volume) , y = Intersection_volume)) +
geom_bar(stat="identity")
})
output$plot2 <- renderPlot({
species_abiotics_df_sub <- species_abiotics_df %>% filter(
species %in% input$species_show
)
ggplot(species_abiotics_df_sub,
aes(x = species_abiotics_df_sub[,input$Factor],
fill = species)) +
geom_density(alpha = 0.4)
})
}
)
}
#___________________________
rescaled_combi_df <- hypervolume_overlap(hv_list)
View(hypervolume_overlap)
install.packages("FishNmix2")
install.packages("FishNmix2")
library(FishNmix2)
View(hypervolume_overlap)
library(FishNmix2)
View(hypervolume_overlap)
remove.packages("FishNmix2")
library(FishNmix2)
View(hypervolume_overlap)
View(hypervolume_overlap)
View(FishNmix2::hypervolume_overlap)
View(FishNmix2::hypervolume_overlap)
View(FishNmix2::hypervolume_overlap)
rescaled_combi_df <- FishNmix2::hypervolume_overlap(hv_list)
globalenv()
memory.limit()
gbif_download <- function(species_list, gbif_user, gbif_pwd, mail){
species_gbifid <- get_gbifid_(species_list) #gives a list of lists with the 3 first results in gbif for each species
gbif_taxon_keys<-c()
for (i in 1:length(species_gbifid)) {
if (species_gbifid[[c(i,5,1)]] == "EXACT"){ #for each species (i) check "matchtype" (5st list) to make sure that the wanted species corresponds to gbif first result (1)
gbif_taxon_keys <- c(gbif_taxon_keys, species_gbifid[[c(i,1,1)]])  #add "usagekey" (1st list) to the list
}
else { #if the matchtype is not exact, suggest to change species name for gbif 1st result
stop(paste0("!!! Warning !!! Species '",species_list[i],"' not found, please try again with : ",species_gbifid[[c(i,2)]])) #if the species does not exactly match with gbif 1st result, the algorithm suggest to try first result's "scientificname" (2nd list)
}
}
###Download the data from GBIF,enter username/password/email. Only keeping data with coordinates (The data is loaded on gbif and ready to download)
data <- occ_download(pred_in("taxonKey", gbif_taxon_keys), pred("hasCoordinate", TRUE), format = "SIMPLE_CSV",user, pwd, email)
return(data)
}
data <- gbif_download("Acipenser Sturio")
species_list <- c("Acipenser sturio")
species_gbifid <- get_gbifid_(species_list) #gives a list of lists with the 3 first results in gbif for each species
library(taxize)
library(rgbif)
species_gbifid <- get_gbifid_(species_list) #gives a list of lists with the 3 first results in gbif for each species
gbif_taxon_keys<-c()
for (i in 1:length(species_gbifid)) {
if (species_gbifid[[c(i,5,1)]] == "EXACT"){ #for each species (i) check "matchtype" (5st list) to make sure that the wanted species corresponds to gbif first result (1)
gbif_taxon_keys <- c(gbif_taxon_keys, species_gbifid[[c(i,1,1)]])  #add "usagekey" (1st list) to the list
}
else { #if the matchtype is not exact, suggest to change species name for gbif 1st result
stop(paste0("!!! Warning !!! Species '",species_list[i],"' not found, please try again with : ",species_gbifid[[c(i,2)]])) #if the species does not exactly match with gbif 1st result, the algorithm suggest to try first result's "scientificname" (2nd list)
}
}
###Download the data from GBIF,enter username/password/email. Only keeping data with coordinates (The data is loaded on gbif and ready to download)
data <- occ_download(pred_in("taxonKey", gbif_taxon_keys), pred("hasCoordinate", TRUE), format = "SIMPLE_CSV",user, pwd, email)
data <- occ_download(pred_in("taxonKey", gbif_taxon_keys), pred("hasCoordinate", TRUE), format = "SIMPLE_CSV","gregoirebutruille", "T&mbetta1", "gregoire.butruille@agrocampus-ouest.fr")
data <- occ_download(pred_in("taxonKey", gbif_taxon_keys), pred("hasCoordinate", TRUE), format = "SIMPLE_CSV",gbif_user ="gregoirebutruille", "T&mbetta1", "gregoire.butruille@agrocampus-ouest.fr")
my_download<-occ_download_get(gbif_data[1],overwrite=TRUE)
print(gbif_citation(gbif_zip_download))
unzip(gbif_zip_download)
print("Downloading datasets from EarthEnv.../n")
print("Downloading datasets from EarthEnv.../n")
print("Downloading datasets from EarthEnv...\n")
for (i in 1:10){
print("Downloading datasets from EarthEnv...\n")
}
cat("Downloading datasets from EarthEnv...\n")
if ("EarthEnv" %in% databases_to_use ){
for (i in 1:10){
cat("Downloading datasets from EarthEnv...\n")
}
download.file("https://data.earthenv.org/streams/hydroclim_average+sum.nc",
paste(getwd(), "hydro_avg.nc", sep="/"), mode = "wb")
download.file("https://data.earthenv.org/streams/soil_maximum.nc",
paste(getwd(), "soil_max.nc", sep="/"), mode = "wb")
download.file("https://data.earthenv.org/streams/elevation.nc",
paste(getwd(), "elevation.nc", sep="/"), mode = "wb")
download.file("https://data.earthenv.org/streams/slope.nc",
paste(getwd(), "slope.nc", sep="/"), mode = "wb")
}
for (i in 1:10){
cat("Downloading datasets from EarthEnv...\n")
}
download.file("https://biogeo.ucdavis.edu/data/worldclim/v2.1/base/wc.1_10m_srad.zip", paste(getwd(), "srad_zip.zip", sep="/"), mode = "wb")
usethis::use_package("progress")
log(length(1000))
warnings()
log(1000)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
library(FishNmix2)
